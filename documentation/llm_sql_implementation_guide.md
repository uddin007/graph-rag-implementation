# LLM SQL generation system

An intelligent SQL generation system that automatically:
1. Uses rule-based SQL for simple queries (fast, <1 sec)
2. Falls back to LLM (Claude Sonnet 4.5) for complex queries (smart, 3-5 sec)

---

### **Enable (Default):**

```python
# Build system
rag_system = GraphRAGSystem(config, spark)
rag_system.build()

# Enable all enhancements (LLM fallback ON by default)
enhance_with_all(rag_system)

# Supports complex queries
rag_system.query("Items with above-average revenue per unit")
```

### **Disable:**

```python
# Disable LLM fallback
from graph_rag_enhancements import enhance_with_sql_queries

enhance_with_sql_queries(rag_system, use_llm_fallback=False)

# Only rule-based SQL
```

---

### **Decision Flow:**

<img width="1024" height="1024" alt="Gemini_Generated_Image_8juxo28juxo28jux" src="https://github.com/user-attachments/assets/59346a95-d2fe-43e0-9b06-d91f7a5b118c" />

### **Example Routing:**

| Query | Method | Use case |
|-------|--------|------|
| "Top 5 items by revenue" | Rule-based | Simple aggregation  |
| "Items above average revenue/unit" | LLM | Needs subquery  |
| "Show chocolate items" | Semantic | Not SQL  |

---

##  Queries Handle by LLM

### **Complex Queries LLM Can Generate:**

```python
#  Subqueries / Aggregates
"Items with above-average revenue per unit sold"
"Customers who spent more than the average customer"

#  Multi-condition filtering
"Customers who only bought items priced above $50"
"Items sold in all three locations"

#  Advanced calculations
"Calculate revenue contribution percentage for each item"
"Show month-over-month revenue growth"

#  Comparative analysis
"Items popular in Seattle but not Portland"
"Customers with purchase frequency above median"

#  Statistical queries
"Show items where sales variance is highest"
"Customers with the most consistent purchase amounts"
```

### **Simple Queries Rule-Based Handles:**

```python
#  Basic aggregations
"Top 10 customers by revenue"
"Bottom 5 items by sales"

#  Time filtering
"Top items in December 2025"
"Customers who bought in Q4"

#  Simple counts
"How many customers bought items?"
```

---

##  Fallback Trigger

### **Automatic Detection:**

```python
# Rule-based CAN handle:
intent = {
    'is_aggregation': True,
    'measure': 'total_sales_value',  #  Found
    'entity_type': 'item_details',   #  Found
    'limit': 5                       #  Found
}
→ Use rule-based SQL

# Rule-based CANNOT handle:
intent = {
    'is_aggregation': True,
    'measure': None,                  #  Complex calculation
    'entity_type': 'item_details',   
    'limit': None                     #  No clear limit
}
→ Use LLM fallback
```

---

##  LLM SQL Generation

```python
# LLM receives:
1. Database schema
   - Fact table: items_sales
   - Dimensions: item_details, store_location, customer_details
   - Foreign keys
   
2. Question
   - "Items with above-average revenue per unit sold"
   
3. Instructions
   - Generate SQL only
   - Use proper JOINs
   - Return executable code
```

### **LLM Returns:**

```sql
SELECT 
    d.item_id,
    d.item_name,
    SUM(f.total_sales_value) / SUM(f.units_sold) as revenue_per_unit
FROM accenture.sales_analysis.items_sales f
JOIN accenture.sales_analysis.item_details d 
    ON f.item_id = d.item_id
GROUP BY d.item_id, d.item_name
HAVING revenue_per_unit > (
    SELECT AVG(SUM(total_sales_value) / SUM(units_sold))
    FROM accenture.sales_analysis.items_sales
    GROUP BY item_id
)
ORDER BY revenue_per_unit DESC
```

---

##  Performance

| Method | Response Time | Use Case |
|--------|---------------|----------|
| Rule-based SQL | 0.5-1 sec | Simple queries (80%) |
| LLM Fallback | 3-5 sec | Complex queries (20%) |
| Semantic Search | 1-2 sec | Exploratory queries |

---

### **1. Handles Complex Queries**
```python
# Before (without LLM):
query = "Items with above-average revenue"
- Falls back to semantic search

# After (with LLM):
query = "Items with above-average revenue"
- LLM generates SQL 
```
### **2. No Manual SQL Writing**
```python
# User doesn't need to know SQL
rag_system.query("Show items where Seattle sales are 2x Portland")

# System generates:
# SELECT ... WHERE seattle_sales > 2 * portland_sales ...
```

### **3. Graceful Degradation**
```python
# If LLM fails:
- Falls back to semantic search
```

---
### **Example 1: Simple -> Rule-Based**

```python
query = "Top 5 items by revenue"

# System detects:
# - "top": aggregation 
# - "revenue": measure 
# - "items": entity 

# Routes to: Rule-based SQL
```

### **Example 2: Complex -> LLM**

```python
query = "Items with revenue above the median"

# System detects:
# - "median": complex calculation
# - Cannot use simple template

# Routes to: LLM query generation
# SQL: Generated by Claude Sonnet 4.5
```

### **Example 3: Not SQL -> Semantic**

```python
query = "Show chocolate items"

# System detects:
# - No aggregation keywords
# - Semantic search needed

# Routes to: Vector search
# Method: Embeddings
```

---

## Configuration

```python
enhance_with_all(rag_system)  # use_llm_fallback=True by default
```
### **Disable LLM:**

```python
# Only rule-based SQL
enhance_with_sql_queries(rag_system, use_llm_fallback=False)
```

### **Custom LLM Endpoint:**

```python
# Modify llm_sql_generator.py
class LLMSQLGenerator:
    def __init__(self, config, spark):
        # Endpoint
        self.endpoint_url = "https://your-endpoint/invocations"
```

**NOTE**
- Claude Sonnet 4.5 charges per token. But only for complex queries.
- To use different model, we need modify `llm_sql_generator.py`.
- System validates SQL before execution. If invalid, falls back to semantic search.
- To see generated SQL, we need to set `verbose=True`.
- LLM reads your schema automatically from the config.

---

